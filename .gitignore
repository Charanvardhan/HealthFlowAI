llama-3.2-local/

# Ignore all .env files
*.env


*.safetensors
*.pth
*.bin
*.ckpt
*.h5

# Ignore cache directories
__pycache__/
.ipynb_checkpoints/
cache/